{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba308fce-27f6-48a0-948b-7121d05a7d22",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1b76349-871b-4150-8184-296cc41e7a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from pathlib import Path\n",
    "import seaborn as sns \n",
    "import sklearn\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86ce74ab-38aa-4e4d-9745-26c98fe9cdbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The notebook is not running on Colab. colab=False.\n"
     ]
    }
   ],
   "source": [
    "# This is a quick check of whether the notebook is currently running on Google Colaboratory, as that makes some difference for the code below.\n",
    "# We'll do this in every notebook of the course.\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    print('The notebook is running on Colab. colab=True.')\n",
    "    colab=True\n",
    "else:\n",
    "    print('The notebook is not running on Colab. colab=False.')\n",
    "    colab=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3defd80b-5db9-4980-96a1-ba40b6b99aa2",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09fd82da-3e6a-4508-8012-de2afde425da",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_DIR = Path.cwd()\n",
    "DATA = NB_DIR/'data'\n",
    "DATA.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dc3b60-6e3f-4b6c-a7bb-2d266651ead4",
   "metadata": {},
   "source": [
    "La oss bruke datasettet fra innlevering 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9e2233d-2a2b-452e-8953-16968da51967",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebb7e961-6c83-46a2-903a-f301450a51ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>...</th>\n",
       "      <th>f_66</th>\n",
       "      <th>f_67</th>\n",
       "      <th>f_68</th>\n",
       "      <th>f_69</th>\n",
       "      <th>f_70</th>\n",
       "      <th>f_71</th>\n",
       "      <th>f_72</th>\n",
       "      <th>f_73</th>\n",
       "      <th>f_74</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>161363</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78028</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110279</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   f_0  f_1  f_2  f_3  f_4  f_5  f_6  f_7   f_8  ...  f_66  f_67  \\\n",
       "0  161363   1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0   0.0  ...   0.0   8.0   \n",
       "1   78028  16.0  0.0  1.0  1.0  6.0  2.0  2.0  2.0  14.0  ...   0.0  41.0   \n",
       "2   35324   0.0  3.0  0.0  1.0  1.0  0.0  0.0  0.0   2.0  ...   0.0   0.0   \n",
       "3   67966   0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   0.0  ...   0.0   0.0   \n",
       "4  110279   3.0  0.0  0.0  2.0  0.0  0.0  0.0  2.0   NaN  ...   0.0   0.0   \n",
       "\n",
       "   f_68  f_69  f_70  f_71  f_72  f_73  f_74  target  \n",
       "0   0.0   0.0   0.0   NaN   NaN   0.0   0.0       6  \n",
       "1   3.0   0.0   0.0   0.0   2.0   1.0   1.0       7  \n",
       "2   0.0   1.0   1.0   0.0   1.0   0.0   0.0       5  \n",
       "3   0.0   2.0   0.0   0.0   0.0   0.0   0.0       1  \n",
       "4   1.0   5.0   4.0   0.0   0.0   0.0   1.0       5  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c80fb90-ff21-43a4-9fa7-427a4a315f7f",
   "metadata": {},
   "source": [
    "# Forbered data for maskinlæring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fdc0858-5c0c-470b-b796-6a40e18fa279",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y  = df.drop([\"id\", \"target\"], axis=1), df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b102f41-8f94-40b3-bc69-2bee5423d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "544a7beb-c74a-4a0e-9638-bc53cefa8be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac37e242-3203-4097-8c5a-c396c2776c0d",
   "metadata": {},
   "source": [
    "Som vi vet må vi imputere manglende verdier og skalere features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "746df509-61a7-4e17-9376-2cc5efc2bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cfff366-0434-466f-b7ba-e371e805e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(strategy='mean')\n",
    "X_train_imp = imp.fit_transform(X_train)\n",
    "X_test_imp = imp.transform(X_test)\n",
    "\n",
    "# We store the results as data frames, for convenience:\n",
    "X_train = pd.DataFrame(data=X_train_imp, columns=X_train.columns)\n",
    "X_test = pd.DataFrame(data=X_test_imp, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72921649-ba5b-4855-b269-8f44cd25aba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = MinMaxScaler()\n",
    "X_train_sc = scale.fit_transform(X_train)\n",
    "X_test_sc = scale.transform(X_test)\n",
    "\n",
    "X_train = pd.DataFrame(data=X_train_sc, columns=X_train.columns)\n",
    "X_test = pd.DataFrame(data=X_test_sc, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7aba8362-eae2-4192-bc04-ab3341e24ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>...</th>\n",
       "      <th>f_65</th>\n",
       "      <th>f_66</th>\n",
       "      <th>f_67</th>\n",
       "      <th>f_68</th>\n",
       "      <th>f_69</th>\n",
       "      <th>f_70</th>\n",
       "      <th>f_71</th>\n",
       "      <th>f_72</th>\n",
       "      <th>f_73</th>\n",
       "      <th>f_74</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392308</td>\n",
       "      <td>0.019231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.171053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.523077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        f_0       f_1       f_2       f_3       f_4       f_5  f_6  f_7  \\\n",
       "0  0.032787  0.019608  0.390625  0.014286  0.026316  0.000000  0.0  0.0   \n",
       "1  0.000000  0.000000  0.000000  0.014286  0.000000  0.000000  0.0  0.0   \n",
       "2  0.163934  0.019608  0.171875  0.000000  0.105263  0.171053  0.0  0.0   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.013158  0.0  0.0   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.013158  0.0  0.0   \n",
       "\n",
       "        f_8       f_9  ...      f_65  f_66      f_67      f_68      f_69  \\\n",
       "0  0.157895  0.013889  ...  0.000000   0.0  0.022987  0.000000  0.000000   \n",
       "1  0.184211  0.000000  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
       "2  0.026316  0.027778  ...  0.018519   0.0  0.063291  0.000000  0.523077   \n",
       "3  0.000000  0.013889  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  ...  0.000000   0.0  0.000000  0.018182  0.000000   \n",
       "\n",
       "   f_70      f_71      f_72      f_73      f_74  \n",
       "0   0.0  0.000000  0.000000  0.392308  0.019231  \n",
       "1   0.0  0.000000  0.000000  0.000000  0.012253  \n",
       "2   0.0  0.333333  0.016393  0.076923  0.000000  \n",
       "3   0.0  0.000000  0.000000  0.000000  0.000000  \n",
       "4   0.0  0.000000  0.016393  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85e75cf-67d5-45a2-9f78-156547cf837b",
   "metadata": {},
   "source": [
    "# Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d5fc76-5f18-4b02-b43a-095286c534f7",
   "metadata": {},
   "source": [
    "Som vi har sett på finnes det mange ulike måter å bygge ensembles fra et sett med modeller. Noen relativt enkle fremgangsmåter, andre mer avanserte. \n",
    "\n",
    "Her er en relativt enkel en:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde389d9-473f-4a72-b0d4-7809514d2bc9",
   "metadata": {},
   "source": [
    "# \"Voting\" og \"model averaging\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cfe46b-ea3f-4bfc-a008-d5bf39cbad0e",
   "metadata": {},
   "source": [
    "Som vi husker fra Random Forests kan det være en god idé å trene flere ulike modeller på samme oppgave, og så kombinere deres prediksjoner ved _avstemming_ (hvis klassifikasjon) eller ved å ta gjennomsnitt (hvis regresjon). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab0bfde-2a8d-4f1e-9615-bbf0cad94892",
   "metadata": {},
   "source": [
    "Denne ideen er mer generell enn random forests: det er ikke nødvendig at hvert medlem i ensemblet er av samme type (beslutningstrær for random forests). En kan trene mange _ulike_ typer modeller, og så kombinere de i et slikt ensemble. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d1b729-5825-4149-80a9-adb10028912b",
   "metadata": {},
   "source": [
    "Vi kan bruke scikit-learn's `VotingClassifer` og `VotingRegressor` til dette:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cc5daf-20a3-45c9-868e-f4d906c4c475",
   "metadata": {},
   "source": [
    "> NB!: Før man begynner å ensemble modeller vil en typisk allerede ha gjennomført hyperparameteroptimalisering for hvert medlem av ensemblet. Altså, en bør først forsøke å øke ytelsen til hvert medlem før en kombinerer de i et ensemble (og forøker å øke ytelsen til ensemblet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21060244-4820-4719-8d44-5fbf7daac7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19147edd-c058-4683-883a-3db700313f64",
   "metadata": {},
   "source": [
    "Her er et eksempel der vi bruker mange _litt_ ulike versjoner av samme modell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "daaec1a1-813d-496b-ac6c-7464e0d383bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a61c4d28-615c-4396-9612-d9074b58667b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_models = 20\n",
    "seed=42\n",
    "\n",
    "models = [(f'rf{i}', RandomForestClassifier(random_state=seed+i, n_jobs=-1)) for i in range(n_models)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2db903d-e324-4bb5-893a-19a4f68f5770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rf0', RandomForestClassifier(n_jobs=-1, random_state=42)),\n",
       " ('rf1', RandomForestClassifier(n_jobs=-1, random_state=43)),\n",
       " ('rf2', RandomForestClassifier(n_jobs=-1, random_state=44)),\n",
       " ('rf3', RandomForestClassifier(n_jobs=-1, random_state=45)),\n",
       " ('rf4', RandomForestClassifier(n_jobs=-1, random_state=46)),\n",
       " ('rf5', RandomForestClassifier(n_jobs=-1, random_state=47)),\n",
       " ('rf6', RandomForestClassifier(n_jobs=-1, random_state=48)),\n",
       " ('rf7', RandomForestClassifier(n_jobs=-1, random_state=49)),\n",
       " ('rf8', RandomForestClassifier(n_jobs=-1, random_state=50)),\n",
       " ('rf9', RandomForestClassifier(n_jobs=-1, random_state=51)),\n",
       " ('rf10', RandomForestClassifier(n_jobs=-1, random_state=52)),\n",
       " ('rf11', RandomForestClassifier(n_jobs=-1, random_state=53)),\n",
       " ('rf12', RandomForestClassifier(n_jobs=-1, random_state=54)),\n",
       " ('rf13', RandomForestClassifier(n_jobs=-1, random_state=55)),\n",
       " ('rf14', RandomForestClassifier(n_jobs=-1, random_state=56)),\n",
       " ('rf15', RandomForestClassifier(n_jobs=-1, random_state=57)),\n",
       " ('rf16', RandomForestClassifier(n_jobs=-1, random_state=58)),\n",
       " ('rf17', RandomForestClassifier(n_jobs=-1, random_state=59)),\n",
       " ('rf18', RandomForestClassifier(n_jobs=-1, random_state=60)),\n",
       " ('rf19', RandomForestClassifier(n_jobs=-1, random_state=61))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b07b704-3c27-49d1-955b-6c7e8dd5692a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = VotingClassifier(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86fdc01b-6995-4aad-adf4-7009294ff54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf0',\n",
       "                              RandomForestClassifier(n_jobs=-1,\n",
       "                                                     random_state=42)),\n",
       "                             ('rf1',\n",
       "                              RandomForestClassifier(n_jobs=-1,\n",
       "                                                     random_state=43)),\n",
       "                             ('rf2',\n",
       "                              RandomForestClassifier(n_jobs=-1,\n",
       "                                                     random_state=44)),\n",
       "                             ('rf3',\n",
       "                              RandomForestClassifier(n_jobs=-1,\n",
       "                                                     random_state=45)),\n",
       "                             ('rf4',\n",
       "                              RandomForestClassifier(n_jobs=-1,\n",
       "                                                     random_state=46)),\n",
       "                             ('rf5',\n",
       "                              RandomForestClassifier(n...\n",
       "                             ('rf14',\n",
       "                              RandomForestClassifier(n_jobs=-1,\n",
       "                                                     random_state=56)),\n",
       "                             ('rf15',\n",
       "                              RandomForestClassifier(n_jobs=-1,\n",
       "                                                     random_state=57)),\n",
       "                             ('rf16',\n",
       "                              RandomForestClassifier(n_jobs=-1,\n",
       "                                                     random_state=58)),\n",
       "                             ('rf17',\n",
       "                              RandomForestClassifier(n_jobs=-1,\n",
       "                                                     random_state=59)),\n",
       "                             ('rf18',\n",
       "                              RandomForestClassifier(n_jobs=-1,\n",
       "                                                     random_state=60)),\n",
       "                             ('rf19',\n",
       "                              RandomForestClassifier(n_jobs=-1,\n",
       "                                                     random_state=61))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1573dfd1-27b5-460c-af74-8ed8426a7a82",
   "metadata": {},
   "source": [
    "> Default innstilling for `VotingClassifier` er såkalt uvektet \"hard voting\". Det betyr at hver modells stemme teller like mye, og at en teller opp output-prediksjonene for å finne hvem som vant majoriteten. Begge disse strategiene kan justeres. For eksempel kan man velge `voting=\"soft\"` for å bruke modellenes _konfidens_ for prediksjonene og ikke bare hver enkelt modells endelige stemme. En modell som er veldig sikker i sin prediksjon vil da gis større vekt enn en modell som er mer usikker. Fritt frem å forsøke denne og andre strategier ved å modifisere på koden!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f37c5db-ae2d-4e6f-80b0-26ef89b254bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\torstein\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 356, in _sendback_result\n    result_queue.put(_ResultItem(work_id, result=result,\n  File \"C:\\Users\\torstein\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\queues.py\", line 241, in put\n    obj = dumps(obj, reducers=self._reducers)\n  File \"C:\\Users\\torstein\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\reduction.py\", line 271, in dumps\n    dump(obj, buf, reducers=reducers, protocol=protocol)\n  File \"C:\\Users\\torstein\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\reduction.py\", line 264, in dump\n    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)\n  File \"C:\\Users\\torstein\\anaconda3\\lib\\site-packages\\joblib\\externals\\cloudpickle\\cloudpickle_fast.py\", line 563, in dump\n    return Pickler.dump(self, obj)\n  File \"C:\\Users\\torstein\\anaconda3\\lib\\site-packages\\joblib\\_memmapping_reducer.py\", line 309, in reduce_array_memmap_backward\n    loads, (dumps(np.asarray(a), protocol=HIGHEST_PROTOCOL), )\nMemoryError\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-8735dc9476eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mensemble\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[0mtransformed_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mle_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformed_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m     72\u001b[0m                              % (len(self.weights), len(self.estimators)))\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[0;32m     75\u001b[0m                 delayed(_fit_single_estimator)(\n\u001b[0;32m     76\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\u001b[0m in \u001b[0;36m_fit_single_estimator\u001b[1;34m(estimator, X, y, sample_weight, message_clsname, message)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    388\u001b[0m                              \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'threads'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd4d16d-a828-4aa7-8dd5-a24a382cfe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb2b5d4-b735-48af-8dd0-c5d02efcb924",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, ensemble.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0e6360-835d-4d3d-8a60-2f78e0788ff6",
   "metadata": {},
   "source": [
    "Bedre enn hver av modellene for seg selv!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e49c6b6b-d3f6-4227-a072-c51f28185267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy til modell rf0: 0.35274666666666665\n",
      "\n",
      "Accuracy til modell rf1: 0.35258666666666666\n",
      "\n",
      "Accuracy til modell rf2: 0.35256\n",
      "\n",
      "Accuracy til modell rf3: 0.3517866666666667\n",
      "\n",
      "Accuracy til modell rf4: 0.35285333333333335\n",
      "\n",
      "Accuracy til modell rf5: 0.3525066666666667\n",
      "\n",
      "Accuracy til modell rf6: 0.35234666666666664\n",
      "\n",
      "Accuracy til modell rf7: 0.35018666666666665\n",
      "\n",
      "Accuracy til modell rf8: 0.35392\n",
      "\n",
      "Accuracy til modell rf9: 0.3528266666666667\n",
      "\n",
      "Accuracy til modell rf10: 0.3512\n",
      "\n",
      "Accuracy til modell rf11: 0.35328\n",
      "\n",
      "Accuracy til modell rf12: 0.3521066666666667\n",
      "\n",
      "Accuracy til modell rf13: 0.3508266666666667\n",
      "\n",
      "Accuracy til modell rf14: 0.3510666666666667\n",
      "\n",
      "Accuracy til modell rf15: 0.35064\n",
      "\n",
      "Accuracy til modell rf16: 0.35042666666666666\n",
      "\n",
      "Accuracy til modell rf17: 0.3508266666666667\n",
      "\n",
      "Accuracy til modell rf18: 0.3538133333333333\n",
      "\n",
      "Accuracy til modell rf19: 0.35061333333333333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in models:\n",
    "    m[1].fit(X_train, y_train)\n",
    "    acc = accuracy_score(y_test, m[1].predict(X_test))\n",
    "    print(f'Accuracy til modell {m[0]}: {acc}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8507dc5c-a2a3-4e8a-910a-7c45e516929b",
   "metadata": {},
   "source": [
    "Men vi behøver altså ikke bruke små variasjoner av samme modell mange ganger. Vi kan ofte med fordel bruke mange ulike modeller. \n",
    "\n",
    "> Siden datasettet i innlevering 1 er så stort vil mange av modellene bruke lang tid på trening. Vi bruker derfor et annet, mindre datasett nedenfor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fed7b86a-e331-4a30-a058-3bafce4ec9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://assets.datacamp.com/production/course_1939/datasets/diabetes.csv')\n",
    "\n",
    "X, y  = df.drop('diabetes', axis=1), df.diabetes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "scale = MinMaxScaler()\n",
    "\n",
    "X_train = scale.fit_transform(X_train)\n",
    "X_test = scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14ccc092-6131-4b3e-ac38-52bb1baffc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>triceps</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>dpf</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  diastolic  triceps  insulin   bmi    dpf  age  \\\n",
       "0            6      148         72       35        0  33.6  0.627   50   \n",
       "1            1       85         66       29        0  26.6  0.351   31   \n",
       "2            8      183         64        0        0  23.3  0.672   32   \n",
       "3            1       89         66       23       94  28.1  0.167   21   \n",
       "4            0      137         40       35      168  43.1  2.288   33   \n",
       "\n",
       "   diabetes  \n",
       "0         1  \n",
       "1         0  \n",
       "2         1  \n",
       "3         0  \n",
       "4         1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0de129b2-ed7b-42a8-8975-9cf44ec496d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b053d585-5a02-45d5-b35c-04f4b9aac0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "svc = SVC(random_state=42)\n",
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01e614ef-b3cd-4081-a7c2-b04716b4348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [('rf', rf), \n",
    "          ('gb', gb),\n",
    "          ('svc', svc),\n",
    "          ('gnb', gnb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da34855f-74a4-430b-b66f-80d96a8a629b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf',\n",
       "                              RandomForestClassifier(n_jobs=-1,\n",
       "                                                     random_state=42)),\n",
       "                             ('gb',\n",
       "                              GradientBoostingClassifier(random_state=42)),\n",
       "                             ('svc', SVC(random_state=42)),\n",
       "                             ('gnb', GaussianNB())])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble = VotingClassifier(models)\n",
    "ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f5101ee-128d-4db2-8f94-a69e9613e8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, ensemble.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e613cc-3073-46e0-9193-93133dc99d30",
   "metadata": {},
   "source": [
    "Bedre enn hver modell hver for seg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65ea9209-086a-4104-9058-726520abff4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7395833333333334\n",
      "\n",
      "Accuracy: 0.7395833333333334\n",
      "\n",
      "Accuracy: 0.7395833333333334\n",
      "\n",
      "Accuracy: 0.734375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in models:\n",
    "    m[1].fit(X_train, y_train)\n",
    "    acc = accuracy_score(y_test, m[1].predict(X_test))\n",
    "    print(f'Accuracy: {acc}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa3fb82-d54b-4f66-adcf-65b42fd2703e",
   "metadata": {},
   "source": [
    "Du må gjerne utforske de mange andre mulighetene i scikit-learn (se f.eks. https://scikit-learn.org/stable/supervised_learning.html) og utenfor scikit-learn (f.eks. LightGBM og XGBoost)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef7be63-d40a-4126-b790-da94e75ba69e",
   "metadata": {},
   "source": [
    "# Andre, mer avanserte teknikker og bibliotek\n",
    "\n",
    "Det er flere bibliotek for ensembling som kan resultere i kraftigere modeller enn det scikit-learn kan konsturere. To mye brukte (som du fort kommer borti på Kaggle-konkurranser!) er \n",
    "\n",
    "- LightGBM: Et mye brukt bibliotek for \"boosting\". Ta en titt på dokumentasjonen her: https://lightgbm.readthedocs.io/en/latest/index.html\n",
    "- XGBoost: Et annet mye brukt bibliotek. Her er noen kilder som forklarer hvordan XGBoost fungerer og hvordan du effektivt kan bruke XGBoost: https://xgboost.readthedocs.io/en/latest, https://www.analyticsvidhya.com/blog/2018/09/an-end-to-end-guide-to-understand-the-math-behind-xgboost, https://campus.datacamp.com/courses/extreme-gradient-boosting-with-xgboost/classification-with-xgboost\n",
    "\n",
    "En generell teknikk vi nevnte i forelesningen er **stacking**, der flere ulike modeller kombineres ved at man trener en **blender** (istedenfor enkel voting). Hvis du vil teste dette ut, ta en titt på scikit-learns `StackingClassifier` og `StackingRegressor`, eller ML-Ensemble https://github.com/flennerhag/mlens og vecstack https://github.com/vecxoz/vecstack.\n",
    "\n",
    "<img width=30% src=\"assets/stack.png\">\n",
    "\n",
    "Hva hvis det var mulig å automatisk velge modeller _dynamisk_ når en predikerer? Altså, for et gitt datapunkt, bruke klassifikatorene som en anslår som mest lovende for akkurat dette datapunktet? Dette kan kalles **dynamic ensemble selection** eller **dynamic classifier selection**, og finnes for eksempel i biblioteket DESlib: https://github.com/scikit-learn-contrib/DESlib, https://deslib.readthedocs.io/en/latest/. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dea4a2-5adb-407d-9a81-d314e612112a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
